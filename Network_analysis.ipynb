{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import celloracle as co\n",
    "co.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization settings\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [6, 4.5]\n",
    "plt.rcParams[\"savefig.dpi\"] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder for data\n",
    "save_folder_data = \"data\"\n",
    "os.makedirs(save_folder_data, exist_ok=True)\n",
    "\n",
    "# Create folder for figures\n",
    "save_folder_figures = \"figures\"\n",
    "os.makedirs(save_folder_figures, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can load files with the following command.\n",
    "links = co.load_hdf5(file_path= os.path.join(save_folder_data, \"day14_preprocessed_links.celloracle.links\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve filtered network data\n",
    "GRN_df_cycling = links.filtered_links[links.cluster[0]]\n",
    "GRN_df_moderate_cyclers = links.filtered_links[links.cluster[1]]\n",
    "GRN_df_non_cycling = links.filtered_links[links.cluster[2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. General checks and data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check if the nodes are all as both node and target\n",
    "\n",
    "# Cycling\n",
    "nodes_out_cycling = GRN_df_cycling['source'].unique()\n",
    "nodes_in_cycling = GRN_df_cycling['target'].unique()\n",
    "print(np.setdiff1d(nodes_out_cycling,nodes_in_cycling))\n",
    "\n",
    "# Moderate cyclers\n",
    "nodes_out_moderate_cyclers = GRN_df_moderate_cyclers['source'].unique()\n",
    "nodes_in_moderate_cyclers = GRN_df_moderate_cyclers['target'].unique()\n",
    "print(np.setdiff1d(nodes_out_moderate_cyclers,nodes_in_moderate_cyclers))\n",
    "\n",
    "# Non-cycling\n",
    "nodes_out_non_cycling = GRN_df_non_cycling['source'].unique()\n",
    "nodes_in_non_cycling = GRN_df_non_cycling['target'].unique()\n",
    "print(np.setdiff1d(nodes_out_non_cycling,nodes_in_non_cycling))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare length of the GRN tables --> number interactions\n",
    "print('nr edges in GRN cycling:', len(GRN_df_cycling))\n",
    "print('nr edges in GRN moderate cyclers:', len(GRN_df_moderate_cyclers))\n",
    "print('nr edges in GRN non-cycling:', len(GRN_df_non_cycling))\n",
    "GRN_df_cycling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each GRN contains 2000 edges, because only the 2000 top ranked edges were considered for the GRN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check nodes per GRN\n",
    "nodes_cycling = GRN_df_cycling['source'].unique()\n",
    "# out_degree_cycling = GRN_df_cycling['source'].value_counts()\n",
    "print('nr source nodes cycling:', len(nodes_cycling))\n",
    "\n",
    "nodes_moderate_cyclers = GRN_df_moderate_cyclers['source'].unique()\n",
    "# out_degree_moderate_cyclers = GRN_df_moderate_cyclers['source'].value_counts()\n",
    "print('nr source nodes moderate cyclers:', len(nodes_moderate_cyclers))\n",
    "\n",
    "nodes_non_cycling = GRN_df_non_cycling['source'].unique()\n",
    "# out_degree_non_cycling = GRN_df_non_cycling['source'].value_counts()\n",
    "print('nr source nodes non-cycling:', len(nodes_non_cycling))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check nodes per GRN\n",
    "nodes_target_cycling = GRN_df_cycling['target'].unique()\n",
    "print('nr target nodes cycling:', len(nodes_target_cycling))\n",
    "\n",
    "nodes_target_moderate_cyclers = GRN_df_moderate_cyclers['target'].unique()\n",
    "print('nr target nodes moderate cyclers:', len(nodes_target_moderate_cyclers))\n",
    "\n",
    "nodes_target_non_cycling = GRN_df_non_cycling['target'].unique()\n",
    "print('nr target nodes non-cycling:', len(nodes_target_non_cycling))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual calculation of out-degree --> Probably not correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Retrieve source TFs (=with out degree) common in all persister type GRNs\n",
    "# common_TFs = np.intersect1d(np.intersect1d(nodes_cycling,nodes_non_cycling), nodes_moderate_cyclers)\n",
    "# print('nr common source TFs in out degree', len(common_TFs))\n",
    "\n",
    "# ## Retrieve unique TFs per persister cell type\n",
    "# print(\"\\nUnique nodes - not present in any other graph/GRN\")\n",
    "# # Cycling\n",
    "# unique_TFs_cycling = np.setdiff1d(np.setdiff1d(nodes_cycling,nodes_non_cycling), nodes_moderate_cyclers)\n",
    "# print('nr unique source TFs in out degree for cycling cells', len(unique_TFs_cycling), ':', unique_TFs_cycling)\n",
    "# # Moderate cyclers\n",
    "# unique_TFs_moderate_cyclers = np.setdiff1d(np.setdiff1d(nodes_moderate_cyclers,nodes_non_cycling), nodes_cycling)\n",
    "# print('nr unique source TFs in out degree for moderate_cycling cells', len(unique_TFs_moderate_cyclers),':',unique_TFs_moderate_cyclers)\n",
    "# # Non-cycling\n",
    "# unique_TFs_non_cycling = np.setdiff1d(np.setdiff1d(nodes_non_cycling,nodes_cycling), nodes_moderate_cyclers)\n",
    "# print('nr unique source TFs in out degree for non-cycling cells', len(unique_TFs_non_cycling),':',unique_TFs_non_cycling)\n",
    "\n",
    "\n",
    "# ## Retrieve TFs per persister cell type which are not present in all GRNs (but they can be in one other GRN)\n",
    "# print(\"\\nUnique nodes compared to common graph nodes\")\n",
    "# # Cycling\n",
    "# unique_TFs_cycling = np.setdiff1d(nodes_cycling,common_TFs)\n",
    "# print('nr unique source TFs in out degree for cycling cells', len(unique_TFs_cycling), ':', unique_TFs_cycling)\n",
    "# # Moderate cyclers\n",
    "# unique_TFs_moderate_cyclers = np.setdiff1d(nodes_moderate_cyclers,common_TFs)\n",
    "# print('nr unique source TFs in out degree for moderate_cycling cells', len(unique_TFs_moderate_cyclers),':',unique_TFs_moderate_cyclers)\n",
    "# # Non-cycling\n",
    "# unique_TFs_non_cycling = np.setdiff1d(nodes_non_cycling,common_TFs)\n",
    "# print('nr unique source TFs in out degree for non-cycling cells', len(unique_TFs_non_cycling),':',unique_TFs_non_cycling)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRN_df_non_cycling#.out_degree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. NetworkX analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph(df, group_name):\n",
    "    \"\"\"\n",
    "    Create a graph of the dataframe obtained from CellOracle.\n",
    "    \"\"\"\n",
    "\n",
    "    print('\\n'+group_name)\n",
    "    G = nx.DiGraph() # Create an empty directed graph\n",
    "\n",
    "    # Add nodes from the 'source' and 'target' columns\n",
    "    G.add_nodes_from(df['source'])\n",
    "    G.add_nodes_from(df['target'])\n",
    "\n",
    "    # Add edges from the DataFrame\n",
    "    edges = [(row['source'], row['target'], row['coef_mean']) for index, row in df.iterrows()]\n",
    "    G.add_weighted_edges_from(edges)\n",
    "\n",
    "    # Graph reporting \n",
    "    print(f\"Number of nodes: {G.number_of_nodes()}\")\n",
    "    print(f\"Number of edges: {G.number_of_edges()}\")\n",
    "\n",
    "    # G['GATA2'] # info of example node\n",
    "    # G.edges['GATA2', 'ADIRF'] # info of example edge\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create graph from each dataframe\n",
    "G_cycling = create_graph(GRN_df_cycling, 'Cycling')\n",
    "G_moderate_cyclers = create_graph(GRN_df_moderate_cyclers, 'Moderate cyclers')\n",
    "G_non_cycling = create_graph(GRN_df_non_cycling, 'Non-cycling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Intersection of the networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get nodes and edges common in all GRNs\n",
    "\n",
    "# Copy of the graph\n",
    "G_common = G_cycling.copy()\n",
    "\n",
    "# Remove nodes and edges that are not the GRN of moderate cyclers\n",
    "G_common.remove_nodes_from(n for n in G_cycling if n not in G_moderate_cyclers) # remove nodes which are not in the moderate cyclers GRN\n",
    "G_common.remove_edges_from(e for e in G_cycling.edges if e not in G_moderate_cyclers.edges) # remove edges which are not in the moderate cyclers GRN\n",
    "print(\"Graph info after removal of nodes and edges not in moderate cycling GRN\")\n",
    "print(f\"Number of nodes: {G_common.number_of_nodes()}\")\n",
    "print(f\"Number of edges: {G_common.number_of_edges()}\")\n",
    "\n",
    "# Remove nodes and edges that are not the GRN of non-cycling cells\n",
    "G_common.remove_nodes_from(n for n in G_cycling if n not in G_non_cycling) # remove nodes which are not in the non-cycling GRN\n",
    "G_common.remove_edges_from(e for e in G_cycling.edges if e not in G_non_cycling.edges) # remove edges which are not in the non-cycling GRN\n",
    "print(\"Graph info after removal of nodes and edges not in non-cycling GRN\")\n",
    "print(f\"Number of nodes: {G_common.number_of_nodes()}\")\n",
    "print(f\"Number of edges: {G_common.number_of_edges()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unique networks (i.e. networks - common network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each graph remove the edges that are in the common graph\n",
    "\n",
    "def remove_common_edges(G, G_common):\n",
    "    # Get copy of the graph\n",
    "    G_unique = G.copy() \n",
    "    print(\"Graph info before removal of edges in common GRN\")\n",
    "    print(f\"Number of nodes: {G_unique.number_of_nodes()}\")\n",
    "    print(f\"Number of edges: {G_unique.number_of_edges()}\")\n",
    "\n",
    "    # Remove edges which are common for all groups\n",
    "    G_unique.remove_edges_from(e for e in G.edges if e in G_common.edges) \n",
    "    print(\"Graph info after removal of edges in common GRN\")\n",
    "    print(f\"Number of nodes: {G_unique.number_of_nodes()}\")\n",
    "    print(f\"Number of edges: {G_unique.number_of_edges()}\")\n",
    "\n",
    "    # Remove isolates (nodes without neighbors) of the graph\n",
    "    G_unique.remove_nodes_from(list(nx.isolates(G_unique)))\n",
    "    print(\"Graph info after removal of isolates\")\n",
    "    print(f\"Number of nodes: {G_unique.number_of_nodes()}\")\n",
    "    print(f\"Number of edges: {G_unique.number_of_edges()}\")\n",
    "    \n",
    "    return G_unique\n",
    "\n",
    "\n",
    "print('cycling')\n",
    "G_cycling_unique = remove_common_edges(G_cycling, G_common)\n",
    "print('\\n'+'moderate cycling')\n",
    "G_moderate_cyclers_unique = remove_common_edges(G_moderate_cyclers, G_common)\n",
    "print('\\n'+'non-cycling')\n",
    "G_non_cycling_unique = remove_common_edges(G_non_cycling, G_common)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Centrality checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Centrality checks for cycling\n",
    "def centrality_checks(G):\n",
    "    \"\"\"\n",
    "    Calculate the in-, out-, and total degree per node of the network/graph. Additionally, sort the nodes based on the degree value in descending order\n",
    "    \"\"\"\n",
    "    total_degree = nx.degree_centrality(G)                                                      # the number of edges each node has\n",
    "    sorted_total_degree = sorted(total_degree.items(), key=lambda item: item[1], reverse=True)  # Sort the dictionary by values in descending order\n",
    "    # print(sorted_total_degree)\n",
    "\n",
    "    out_degree = nx.out_degree_centrality(G)                                                    # the number of edges from a node to targets \n",
    "    sorted_out_degree = sorted(out_degree.items(), key=lambda item: item[1], reverse=True)      # Sort the dictionary by values in descending order\n",
    "    # print(sorted_out_degree)\n",
    "\n",
    "    in_degree = nx.in_degree_centrality(G)                                                      # the number of edges with that node as target\n",
    "    sorted_in_degree = sorted(in_degree.items(), key=lambda item: item[1], reverse=True)        # Sort the dictionary by values in descending order\n",
    "    # print(sorted_in_degree)\n",
    "\n",
    "    return sorted_total_degree, sorted_out_degree, sorted_in_degree\n",
    "\n",
    "\n",
    "# Complete/original networks\n",
    "_,sorted_out_degree_cycling,_ = centrality_checks(G_cycling)\n",
    "_,sorted_out_degree_moderate_cyclers,_ = centrality_checks(G_moderate_cyclers)\n",
    "_,sorted_out_degree_non_cycling,_ = centrality_checks(G_non_cycling)\n",
    "\n",
    "# Network of overlapping nodes and edges\n",
    "_,sorted_out_degree_common,_ = centrality_checks(G_common)\n",
    "\n",
    "# Filtered networks - without edges from the common network\n",
    "_,sorted_out_degree_cycling_unique,_ = centrality_checks(G_cycling_unique)\n",
    "_,sorted_out_degree_moderate_cyclers_unique,_ = centrality_checks(G_moderate_cyclers_unique)\n",
    "_,sorted_out_degree_non_cycling_unique,_ = centrality_checks(G_non_cycling_unique)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original networks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the original networks\n",
    "# convert out-degrees to a dataframe\n",
    "df_out_degree_common = pd.DataFrame(list(sorted_out_degree_common[:10]), columns=['Node_Common', 'Out_Degree_Common'])\n",
    "df_out_degree_cyc = pd.DataFrame(list(sorted_out_degree_cycling[:10]), columns=['Node_Cyc', 'Out_Degree_Cyc'])\n",
    "df_out_degree_mod = pd.DataFrame(list(sorted_out_degree_moderate_cyclers[:10]), columns=['Node_Mod', 'Out_Degree_Mod'])\n",
    "df_out_degree_non_cyc = pd.DataFrame(list(sorted_out_degree_non_cycling[:10]), columns=['Node_Non_cyc', 'Out_Degree_Non_cyc'])\n",
    "\n",
    "# Concatenate the DataFrames column-wise (align by index)\n",
    "merged_df_out_degree = pd.concat([df_out_degree_common, df_out_degree_cyc, df_out_degree_mod, df_out_degree_non_cyc], axis=1)\n",
    "merged_df_out_degree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simplified networks --> where common interactions are removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For unique networks\n",
    "# convert out-degrees to a dataframe\n",
    "df_out_degree_cyc_unique = pd.DataFrame(list(sorted_out_degree_cycling_unique[:10]), columns=['Node_Cyc', 'Out_Degree_Cyc'])\n",
    "df_out_degree_mod_unique = pd.DataFrame(list(sorted_out_degree_moderate_cyclers_unique[:10]), columns=['Node_Mod', 'Out_Degree_Mod'])\n",
    "df_out_degree_non_cyc_unique = pd.DataFrame(list(sorted_out_degree_non_cycling_unique[:10]), columns=['Node_Non_cyc', 'Out_Degree_Non_cyc'])\n",
    "\n",
    "# Concatenate the DataFrames column-wise (align by index)\n",
    "merged_df_out_degree_unique = pd.concat([df_out_degree_common, df_out_degree_cyc_unique, df_out_degree_mod_unique, df_out_degree_non_cyc_unique], axis=1)\n",
    "merged_df_out_degree_unique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df_out_degree_unique[merged_df_out_degree_unique['Node_Cyc']=='SP6']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Common network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the graph for common network\n",
    "pos = nx.spring_layout(G_common) # Define the layout for node positioning\n",
    "nx.draw(G_common, pos, with_labels=True, node_size=300, node_color='skyblue', font_size=10, font_color='black')\n",
    "# Display the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cycling network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Draw the graph for cycling network\n",
    "# pos = nx.spring_layout(G_cycling) # Define the layout for node positioning\n",
    "# nx.draw(G_cycling, pos, with_labels=True, node_size=300, node_color='skyblue', font_size=10, font_color='black')\n",
    "# # Display the graph\n",
    "# plt.show()\n",
    "\n",
    "# Draw the graph for unique cycling network - so with the common interactions removed\n",
    "pos = nx.spring_layout(G_cycling_unique) # Define the layout for node positioning\n",
    "nx.draw(G_cycling_unique, pos, with_labels=True, node_size=300, node_color='skyblue', font_size=10, font_color='black')\n",
    "# Display the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Moderate cyclers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Draw the graph for cycling network\n",
    "# pos = nx.spring_layout(G_moderate_cyclers) # Define the layout for node positioning\n",
    "# nx.draw(G_moderate_cyclers, pos, with_labels=True, node_size=300, node_color='skyblue', font_size=10, font_color='black')\n",
    "# # Display the graph\n",
    "# plt.show()\n",
    "\n",
    "# Draw the graph for unique cycling network - so with the common interactions removed\n",
    "pos = nx.spring_layout(G_moderate_cyclers_unique) # Define the layout for node positioning\n",
    "nx.draw(G_moderate_cyclers_unique, pos, with_labels=True, node_size=300, node_color='skyblue', font_size=10, font_color='black')\n",
    "# Display the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Non-cycling network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Draw the graph for cycling network\n",
    "# pos = nx.spring_layout(G_non_cycling) # Define the layout for node positioning\n",
    "# nx.draw(G_non_cycling, pos, with_labels=True, node_size=300, node_color='skyblue', font_size=10, font_color='black')\n",
    "# # Display the graph\n",
    "# plt.show()\n",
    "\n",
    "# Draw the graph for unique cycling network - so with the common interactions removed\n",
    "pos = nx.spring_layout(G_non_cycling_unique) # Define the layout for node positioning\n",
    "nx.draw(G_non_cycling_unique, pos, with_labels=True, node_size=300, node_color='skyblue', font_size=10, font_color='black')\n",
    "# Display the graph\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_env_celloracle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
