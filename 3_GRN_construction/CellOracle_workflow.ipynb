{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import celloracle as co\n",
    "co.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization settings\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [6, 4.5]\n",
    "plt.rcParams[\"savefig.dpi\"] = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read preprocessed AnnData object\n",
    "adata = sc.read_h5ad('/home/jolien/Notebooks/data/preprocessed_data_day14.h5ad')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action: Configure folder names, depending on selection of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder for specific GRN inference - for each trial a new folder should be defined/called\n",
    "current_trial = \"day14_analysis\"\n",
    "os.makedirs(current_trial, exist_ok=True)\n",
    "\n",
    "# Create folder for data\n",
    "save_folder_data = current_trial+\"/data\"\n",
    "os.makedirs(save_folder_data, exist_ok=True)\n",
    "\n",
    "# Create folder for figures\n",
    "save_folder_figures = current_trial+\"/figures\"\n",
    "os.makedirs(save_folder_figures, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Cell number is :{adata.shape[0]}\")\n",
    "print(f\"Gene number is :{adata.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random downsampling into 30K cells if the anndata object include more than 30 K cells.\n",
    "n_cells_downsample = 30000\n",
    "if adata.shape[0] > n_cells_downsample:\n",
    "    # Let's dowmsample into 30K cells\n",
    "    sc.pp.subsample(adata, n_obs=n_cells_downsample, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Cell number is :{adata.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TF info which was made from mouse cell atlas dataset.\n",
    "base_GRN = co.data.load_human_promoter_base_GRN()\n",
    "\n",
    "# Check data\n",
    "base_GRN.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Make Oracle object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Oracle object\n",
    "oracle = co.Oracle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data in anndata\n",
    "print(\"Metadata columns :\", list(adata.obs.columns))\n",
    "print(\"Dimensional reduction: \", list(adata.obsm.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this notebook, we use the unscaled mRNA count for the input of Oracle object.\n",
    "adata.X = adata.layers[\"raw_count\"].copy()\n",
    "\n",
    "# Instantiate Oracle object.\n",
    "oracle.import_anndata_as_raw_count(adata=adata,\n",
    "                                   cluster_column_name=\"sample_type\",\n",
    "                                   embedding_name=\"X_draw_graph_fa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can load TF info dataframe with the following code.\n",
    "oracle.import_TF_data(TF_info_matrix=base_GRN)\n",
    "\n",
    "# Alternatively, if you saved the informmation as a dictionary, you can use the code below.\n",
    "# oracle.import_TF_data(TFdict=TFinfo_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. KNN imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA\n",
    "oracle.perform_PCA()\n",
    "\n",
    "# Select important PCs\n",
    "plt.plot(np.cumsum(oracle.pca.explained_variance_ratio_)[:100])\n",
    "n_comps = np.where(np.diff(np.diff(np.cumsum(oracle.pca.explained_variance_ratio_))>0.002))[0][0] # retrieves the point/the amount of components where the second derivative (=rate of change of slope) of the cumulative explained variance becomes smaller than the threshold \n",
    "plt.axvline(n_comps, c=\"k\")\n",
    "plt.show()\n",
    "print(n_comps)\n",
    "n_comps = min(n_comps, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cell = oracle.adata.shape[0]\n",
    "print(f\"cell number is :{n_cell}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = int(0.025*n_cell)\n",
    "print(f\"Auto-selected k is :{k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle.knn_imputation(n_pca_dims=n_comps, k=k, balanced=True, b_sight=k*8,\n",
    "                      b_maxl=k*4, n_jobs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Save oracle object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save oracle object.\n",
    "oracle.to_hdf5(os.path.join(save_folder_data,\"Persister_cells_day14.celloracle.oracle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load file.\n",
    "# oracle = co.load_hdf5(os.path.join(save_folder_data,\"Persister_cells_day14.celloracle.oracle\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. GRN calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check clustering data\n",
    "sc.pl.draw_graph(oracle.adata, color=\"sample_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate GRN for each population in \"sample_type\" clustering unit.\n",
    "# This step may take some time.(~30 minutes)\n",
    "links = oracle.get_links(cluster_name_for_GRN_unit=\"sample_type\", alpha=10,\n",
    "                         verbose_level=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get specific GRN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get clusters\n",
    "links.links_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get GRN for a specific cluster\n",
    "links.links_dict[\"Cycling\"] # replace the string with one of the keys from the previous output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export file\n",
    "\n",
    "# Set cluster name\n",
    "cluster = \"Cycling\"\n",
    "\n",
    "# Save as csv\n",
    "#links.links_dict[cluster].to_csv(f\"raw_GRN_for_{cluster}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the contents of pallete - this stores color information which is used when visualizing the clusters. Here we can change both the cluster colors and order.\n",
    "links.palette\n",
    "\n",
    "# # Change the order of pallete\n",
    "# order = ['Cycling','Moderate_cyclers','Non-cycling']\n",
    "# links.palette = links.palette.loc[order]\n",
    "# links.palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Links object.\n",
    "links.to_hdf5(file_path=os.path.join(save_folder_data,\"day14_links.celloracle.links\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check statistics of interactions - how many edges are significant\n",
    "for cluster in links.cluster:\n",
    "    print(cluster)\n",
    "    # check total amount of edges\n",
    "    nr_edges_total = len(links.links_dict[cluster])\n",
    "    print('nr edges in unpreprocessed grns cycling', nr_edges_total)\n",
    "    # check signigicant edges (when p<0.001)\n",
    "    mask_pvalue_edges = links.links_dict[cluster]['p']< 0.001                   # mask for significant edges\n",
    "    nr_edges_significant = len(links.links_dict[cluster][mask_pvalue_edges])    # select siginificant edges and determine the amount\n",
    "    # print('nr edges in unpreprocessed grns cycling', nr_edges_significant)\n",
    "    percentage_significant_edges = nr_edges_significant/nr_edges_total*100      # calculate percentage significant edges\n",
    "    print(\"{:.1f}% of the edges is significant\".format(percentage_significant_edges))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Network preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to remove the weak edges or insignificant edges before doing network structure analysis.\n",
    "\n",
    "1. Remove uncertain network edges based on the p-value.\n",
    "2. Remove weak network edge. In this tutorial, we keep the top 2000 edges ranked by edge strength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter network edges\n",
    "links.filter_links(p=0.001, weight=\"coef_abs\", threshold_number=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the network degree distribution\n",
    "plt.rcParams[\"figure.figsize\"] = [9, 4.5]\n",
    "links.plot_degree_distributions(plot_model=True,\n",
    "                                               save=f\"{save_folder_figures}/degree_distribution/\",\n",
    "                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate network scores.\n",
    "links.get_network_score()\n",
    "\n",
    "# The score is stored as a attribute merged_score.\n",
    "links.merged_score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed GRNs (Links object).\n",
    "links.to_hdf5(file_path= os.path.join(save_folder_data, \"day14_preprocessed_links.celloracle.links\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can load files with the following command.\n",
    "links = co.load_hdf5(file_path= os.path.join(save_folder_data, \"day14_preprocessed_links.celloracle.links\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export file\n",
    "\n",
    "# Save as csv\n",
    "for cluster in links.cluster:\n",
    "    links.filtered_links[cluster].to_csv(os.path.join(save_folder_data, f\"processed_GRN_for_{cluster}.csv\"))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Network analysis; Network score for each gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check minimum and maximum coef_abs per cluster\n",
    "for cluster in links.cluster:\n",
    "    print(cluster)\n",
    "    print('min coef_abs', np.min(links.filtered_links[cluster]['coef_abs']))\n",
    "    print('max coef_abs', np.max(links.filtered_links[cluster]['coef_abs']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(1,3, figsize=(20,5), sharey=True)\n",
    "\n",
    "# axes[0].bar(links.filtered_links['Cycling']['source'], links.filtered_links['Cycling']['coef_abs']);\n",
    "# axes[0].tick_params(rotation=90);\n",
    "\n",
    "# axes[1].bar(links.filtered_links['Moderate_cyclers']['source'], links.filtered_links['Moderate_cyclers']['coef_abs']);\n",
    "# axes[1].tick_params(rotation=90);\n",
    "\n",
    "# axes[2].bar(links.filtered_links['Non-cycling']['source'], links.filtered_links['Non-cycling']['coef_abs']);\n",
    "# axes[2].tick_params(rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top n-th genes with high scores.\n",
    "links.plot_scores_as_rank(cluster=\"Cycling\", n_gene=30)#, save=f\"{save_folder_figures}/ranked_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare GRN score between two clusters\n",
    "links.plot_score_comparison_2D(value=\"eigenvector_centrality\",\n",
    "                               cluster1=\"Cycling\", cluster2=\"Non-cycling\",\n",
    "                               percentile=98,\n",
    "                               save=f\"{save_folder_figures}/score_comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare GRN score between two clusters\n",
    "links.plot_score_comparison_2D(value=\"eigenvector_centrality\",\n",
    "                               cluster1=\"Cycling\", cluster2=\"Moderate_cyclers\",\n",
    "                               percentile=98,\n",
    "                               save=f\"{save_folder_figures}/score_comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare GRN score between two clusters\n",
    "links.plot_score_comparison_2D(value=\"eigenvector_centrality\",\n",
    "                               cluster1=\"Non-cycling\", cluster2=\"Moderate_cyclers\",\n",
    "                               percentile=98,\n",
    "                               save=f\"{save_folder_figures}/score_comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize gene network score dynamics\n",
    "links.plot_score_per_cluster(goi=\"E2F1\", save=f\"{save_folder_figures}/network_score_per_gene/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize gene network score dynamics\n",
    "links.plot_score_per_cluster(goi=\"ATF3\", save=f\"{save_folder_figures}/network_score_per_gene/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the filtered network edge\n",
    "cluster_name = \"Cycling\"\n",
    "filtered_links_df = links.filtered_links[cluster_name]\n",
    "filtered_links_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Network analysis; network score distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the network score distributions to get insight into the global network trends\n",
    "plt.rcParams[\"figure.figsize\"] = [6, 4.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot degree_centrality\n",
    "plt.subplots_adjust(left=0.15, bottom=0.3)\n",
    "plt.ylim([0,0.040])\n",
    "links.plot_score_discributions(values=[\"degree_centrality_all\"],\n",
    "                               method=\"boxplot\",\n",
    "                               save=f\"{save_folder_figures}\",\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot eigenvector_centrality\n",
    "plt.subplots_adjust(left=0.15, bottom=0.3)\n",
    "plt.ylim([0, 0.28])\n",
    "links.plot_score_discributions(values=[\"eigenvector_centrality\"],\n",
    "                               method=\"boxplot\",\n",
    "                               save=f\"{save_folder_figures}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots_adjust(left=0.15, bottom=0.3)\n",
    "links.plot_network_entropy_distributions(save=f\"{save_folder_figures}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_env_celloracle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
