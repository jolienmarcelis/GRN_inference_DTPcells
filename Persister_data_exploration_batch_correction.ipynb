{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import anndata as ad\n",
    "\n",
    "import scanpy as sc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "import bbknn\n",
    "# from numpy import cov\n",
    "# from scipy.stats import pearsonr\n",
    "\n",
    "#import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.rcParams[\"savefig.dpi\"] = 300\n",
    "plt.rcParams[\"figure.figsize\"] = [6, 4.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metaData_with_lineage = pd.read_csv('/data/benchmarks/scRNAseq_persisters/GSE150949_metaData_with_lineage.txt', sep=\"\\t\")\n",
    "df_metaData_with_lineage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_cells_total = len(df_metaData_with_lineage)\n",
    "nr_cells_no_barcode = sum(df_metaData_with_lineage['lineage_barcode'].isnull())\n",
    "nr_cells_multiple_barcodes = sum(df_metaData_with_lineage['lineage_barcode'].str.contains(',', na=False))\n",
    "\n",
    "print('The total number of cells =',nr_cells_total)\n",
    "print('The number of cells without a lineage barcode =',nr_cells_no_barcode, 'This is equal to ', round((nr_cells_no_barcode/nr_cells_total)*100,1),'%')\n",
    "print('The number of cells with multiple lineage barcodes =', nr_cells_multiple_barcodes,'This is equal to ', round((nr_cells_multiple_barcodes/nr_cells_total)*100,1),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check mitochondrial fraction of cells\n",
    "print('The number of cells with >0.1 mitochondrial fraction is =', len(df_metaData_with_lineage[df_metaData_with_lineage['percent.mito']>0.1]))\n",
    "# check for cells with <1000 genes\n",
    "print('The number of cells with <1000 genes is =', len(df_metaData_with_lineage[df_metaData_with_lineage['nGene']<1000]))\n",
    "# check for cells with >4200 genes\n",
    "print('The number of cells with >4200 genes is =', len(df_metaData_with_lineage[df_metaData_with_lineage['nGene']>4200]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are no cells with >0.1 mitochondrial fraction or with <1000 or >4200 genes, it looks like this data is already preprocessed before by Oren et al. (2021)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_df =df_metaData_with_lineage.copy() # copy of dataframe to make additions\n",
    "\n",
    "# replace sample_type label: from 14_high to non-cycling etc. to avoid confusion\n",
    "copy_df = copy_df.replace('14_high', 'Non-cycling')\n",
    "copy_df = copy_df.replace('14_med', 'Moderate_cyclers')\n",
    "copy_df = copy_df.replace('14_low', 'Cycling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column for info about the fate of the lineage at day 14\n",
    "copy_df['fate_day_14'] = np.nan # create empty column\n",
    "\n",
    "# Put 'Multi lineage' label in fate_day_14 column for cells that have multiple lineages\n",
    "multi_barcode_indices = df_metaData_with_lineage['lineage_barcode'].str.contains(',', na=False)\n",
    "copy_df.loc[multi_barcode_indices, 'fate_day_14'] = 'Multiple lineages'\n",
    "\n",
    "# get index of cycling and non-cycling cells\n",
    "index_non_cycling = copy_df.index[copy_df['sample_type']=='Non-cycling']\n",
    "index_moderate_cyclers = copy_df.index[copy_df['sample_type']=='Moderate_cyclers']\n",
    "index_cycling = copy_df.index[copy_df['sample_type']=='Cycling']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find barcodes of day 14 cells grouped per cell fate \n",
    "def get_unique_barcodes(df, indices_list):\n",
    "    \"\"\"Function to obtain a series object of the unique lineage barcodes of cells measured at day 14, as categoricals.\"\"\"\n",
    "\n",
    "    barcodes = df.loc[indices_list, 'lineage_barcode'] # extract lineage barcodes of day 14 cells from a population with the same cell fate\n",
    "    barcodes = barcodes.astype('category') # convert to categories\n",
    "    barcodes = barcodes.cat.categories # create an object containing all unique lineage barcodes (with the category data type)\n",
    "    \n",
    "    return barcodes\n",
    "\n",
    "barcodes_non_cycling = get_unique_barcodes(copy_df,index_non_cycling) # barcoddes from day 14 cells categorized as non-cycling \n",
    "barcodes_moderate_cyclers = get_unique_barcodes(copy_df,index_moderate_cyclers )# barcoddes from day 14 cells categorized as moderate cyclers\n",
    "barcodes_cycling = get_unique_barcodes(copy_df,index_cycling) # barcoddes from day 14 cells categorized as cycling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find barcodes common between each pair of groups\n",
    "common_noncycling_cycling = barcodes_non_cycling.intersection(barcodes_cycling)\n",
    "common_noncycling_moderatecyclers = barcodes_non_cycling.intersection(barcodes_moderate_cyclers)\n",
    "common_cycling_moderatecyclers = barcodes_cycling.intersection(barcodes_moderate_cyclers)\n",
    "\n",
    "# Remove common barcodes from each group\n",
    "unique_barcodes_non_cycling = barcodes_non_cycling.difference(common_noncycling_cycling.union(common_noncycling_moderatecyclers)) \n",
    "unique_barcodes_cycling = barcodes_cycling.difference(common_noncycling_cycling.union(common_cycling_moderatecyclers))\n",
    "unique_barcodes_moderatecyclers = barcodes_moderate_cyclers.difference(common_noncycling_moderatecyclers.union(common_cycling_moderatecyclers))\n",
    "\n",
    "# Combine all common barcodes --> multi fate lineages \n",
    "multifate_barcodes = common_noncycling_cycling.union(common_noncycling_moderatecyclers).union(common_cycling_moderatecyclers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get indices of cells with lineage barcodes per group\n",
    "all_non_cyclers_indices = copy_df['lineage_barcode'].isin(unique_barcodes_non_cycling)\n",
    "all_moderatecyclers_indices = copy_df['lineage_barcode'].isin(unique_barcodes_moderatecyclers)\n",
    "all_cyclers_indices = copy_df['lineage_barcode'].isin(unique_barcodes_cycling)\n",
    "all_multifate_indices = copy_df['lineage_barcode'].isin(multifate_barcodes)\n",
    "\n",
    "# enter fate in cell fate column\n",
    "copy_df.loc[all_non_cyclers_indices, 'fate_day_14'] = 'Non-cycling'\n",
    "copy_df.loc[all_moderatecyclers_indices, 'fate_day_14'] = 'Moderate_cyclers'\n",
    "copy_df.loc[all_cyclers_indices, 'fate_day_14'] = 'Cycling'\n",
    "copy_df.loc[all_multifate_indices, 'fate_day_14'] = 'Multi-fate'\n",
    "\n",
    "copy_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load count matrix data & create to AnnData object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data using polars (=more effective/efficient than pandas)\n",
    "df_pc9_count_matrix = pl.read_csv('/data/benchmarks/scRNAseq_persisters/GSE150949_pc9_count_matrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pc9_count_matrix.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_names = df_pc9_count_matrix[:, 0].to_list() # Extract gene names (=first column)\n",
    "df_pc9_count_matrix_without_genenames = df_pc9_count_matrix[:, 1:] # Exclude first column which containes the gene names\n",
    "\n",
    "cell_names = df_pc9_count_matrix_without_genenames.columns # Extract names of the cells\n",
    "\n",
    "numpy_count_matrix = df_pc9_count_matrix_without_genenames.to_numpy()  # Convert to a numpy matrix to enable conversion to AnnData object\n",
    "\n",
    "# Create AnnData object\n",
    "adata = ad.AnnData(X=numpy_count_matrix.T,\n",
    "                   var=pd.DataFrame(index=gene_names),\n",
    "                   obs=pd.DataFrame(index=cell_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the number of cells = 56419 and the number of genes = 22166"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter relevant metadata to the AnnData object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter relavant metadata to the AnnData object\n",
    "list_clone_size = df_metaData_with_lineage['clone_size'].to_list()\n",
    "\n",
    "# Get lineage barcode in adata object\n",
    "adata.obs['lineage_barcode']=df_metaData_with_lineage['lineage_barcode']\n",
    "\n",
    "# Get time points as categorical in adata object\n",
    "time_points_cat = df_metaData_with_lineage.time_point.astype('category') # convert dtype from int64 to category (for plotting lateron)\n",
    "adata.obs['time_point'] = time_points_cat # add categorical time points to adata object\n",
    "adata\n",
    "\n",
    "# Get cell fate of lineage at day 14 in adata object\n",
    "fate_day_14_cat = copy_df.fate_day_14.astype('category') # convert dtype to category (for plotting lateron)\n",
    "adata.obs['fate_day_14'] = fate_day_14_cat # add categorical time points to adata object\n",
    "adata\n",
    "\n",
    "# Get time points as categorical in adata object, including cell fate categories for day 14 cells\n",
    "sample_type_cat = copy_df.sample_type.astype('category') # convert dtype to category (for plotting lateron)\n",
    "adata.obs['sample_type'] = sample_type_cat # add categorical time points to adata object\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only consider genes with more than 1 count\n",
    "sc.pp.filter_genes(adata, min_counts=1)\n",
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently there were no zero-count genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize gene expression matrix with total UMI count per cell\n",
    "adata.X = adata.X.astype('float64') # Convert the main data matrix to float64, because normalization was not possible with int64 values\n",
    "sc.pp.normalize_per_cell(adata, key_n_counts='n_counts_all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Identification of highly variable genes\n",
    "\n",
    "Removing non-variable genes reduces the calculation time during the GRN reconstruction and simulation steps. It also improves the overall accuracy of the GRN inference by removing noisy genes. Using the top 2000~3000 variable genes is recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top 2000 highly-variable genes\n",
    "filter_result = sc.pp.filter_genes_dispersion(adata.X,\n",
    "                                              flavor='cell_ranger',\n",
    "                                              n_top_genes=2000,\n",
    "                                              log=False)\n",
    "\n",
    "# Subset the genes\n",
    "adata = adata[:, filter_result.gene_subset]\n",
    "\n",
    "# Renormalize after filtering - making the total expression per cell equal across the dataset\n",
    "sc.pp.normalize_per_cell(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "\n",
    "# adata.var['variability_means'] = filter_result.means\n",
    "# adata.var['variability_dispersions'] = filter_result.dispersions\n",
    "# adata.var['variability_highly_variable'] = filter_result.gene_subset\n",
    "\n",
    "# top10_genes = adata.var[adata.var['variability_highly_variable']].nlargest(10, 'variability_dispersions').index.tolist()\n",
    "\n",
    "\n",
    "# # Plot all genes, highlighting highly variable genes\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.scatterplot(data=adata.var, x='variability_means', y='variability_dispersions', hue='variability_highly_variable', palette=['gray', 'red'], s=10)\n",
    "\n",
    "# # Label the top 10 highly variable genes\n",
    "# for gene in top10_genes:\n",
    "#     plt.text(adata.var.loc[gene, 'variability_means'], adata.var.loc[gene, 'variability_dispersions'], gene, fontsize=8, color='black', ha='right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Log transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep raw count data before log transformation\n",
    "adata.raw = adata\n",
    "adata.layers[\"raw_count\"] = adata.raw.X.copy()\n",
    "\n",
    "# Log transformation \n",
    "sc.pp.log1p(adata) # The \"log1p\" function means taking the natural logarithm of (1 + X) for each value in the expression matrix, the addition of 1 ensures all values, including zeros, are log-transformed without creating NaN values\n",
    "\n",
    "# Keep log_transformed data before scaling\n",
    "adata.layers[\"log_transformed\"] = adata.X.copy()\n",
    "\n",
    "# Scaling \n",
    "sc.pp.scale(adata)\n",
    "\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. PCA and neighbor calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "sc.tl.pca(adata, svd_solver='arpack')\n",
    "\n",
    "# Diffusion map\n",
    "# sc.pp.neighbors(adata, n_neighbors=4, n_pcs=20)\n",
    "bbknn.bbknn(adata, batch_key='time_point', neighbors_within_batch=4, n_pcs=20)\n",
    "\n",
    "sc.tl.draw_graph(adata, random_state=123)\n",
    "sc.pl.draw_graph(adata, color=\"sample_type\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.diffmap(adata)\n",
    "# Calculate neihbors again based on diffusionmap\n",
    "# sc.pp.neighbors(adata, n_neighbors=10, use_rep='X_diffmap')\n",
    "bbknn.bbknn(adata, batch_key='time_point', neighbors_within_batch=10, use_rep='X_diffmap')\n",
    "\n",
    "sc.tl.draw_graph(adata, random_state=123)\n",
    "sc.pl.draw_graph(adata, color=\"sample_type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diffusion map is applied to denoise the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the variance explained by each PC\n",
    "variance_ratio = adata.uns['pca']['variance_ratio']\n",
    "\n",
    "# Create an elbow plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, len(variance_ratio) + 1), variance_ratio, marker='o')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Variance Explained')\n",
    "plt.title('Elbow Plot for PCA')\n",
    "plt.grid(True)\n",
    "# plt.savefig('/home/jolien/Notebooks/data_preprocessing/figures/PCA_elbow_plot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store PC1 and PC2 in adata.obs\n",
    "adata.obs['PC1'] = adata.obsm['X_pca'][:,0] # First principal component\n",
    "adata.obs['PC2'] = adata.obsm['X_pca'][:,1] # Second principal component\n",
    "adata.obs['PC3'] = adata.obsm['X_pca'][:,2] # Third principal component\n",
    "adata.obs['PC4'] = adata.obsm['X_pca'][:,3] # Fourth principal component\n",
    "adata.obs['PC5'] = adata.obsm['X_pca'][:,4] # Fifth principal component\n",
    "adata.obs['PC6'] = adata.obsm['X_pca'][:,5] # Sixt principal component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get explained variance percentage for PC1 and PC2\n",
    "expl_var_pc1 = adata.uns['pca']['variance_ratio'][0]*100\n",
    "expl_var_pc2 = adata.uns['pca']['variance_ratio'][2]*100\n",
    "\n",
    "# Plot PC1 vs PC2\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(adata.obs['PC1'], adata.obs['PC2'], s=5) \n",
    "plt.xlabel('PC1 ({:.1f}%)'.format(expl_var_pc1))\n",
    "plt.ylabel('PC2 ({:.1f}%)'.format(expl_var_pc2))\n",
    "plt.title('PCA Plot of PC1 vs PC2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract PC1 and PC2 for plotting per sample_type group\n",
    "# time = 0\n",
    "pc1_0 = adata.obsm['X_pca'][copy_df['sample_type']=='0', 0]  # First principal component\n",
    "pc2_0 = adata.obsm['X_pca'][copy_df['sample_type']=='0', 1]  # Second principal component\n",
    "\n",
    "# time = 3\n",
    "pc1_3 = adata.obsm['X_pca'][copy_df['sample_type']=='3', 0]  # First principal component\n",
    "pc2_3 = adata.obsm['X_pca'][copy_df['sample_type']=='3', 1]  # Second principal component\n",
    "\n",
    "# time = 7\n",
    "pc1_7 = adata.obsm['X_pca'][copy_df['sample_type']=='7', 0]  # First principal component\n",
    "pc2_7 = adata.obsm['X_pca'][copy_df['sample_type']=='7', 1]  # Second principal component\n",
    "\n",
    "# time = cycling (14_low)\n",
    "pc1_14l = adata.obsm['X_pca'][copy_df['sample_type']=='Cycling', 0]  # First principal component\n",
    "pc2_14l = adata.obsm['X_pca'][copy_df['sample_type']=='Cycling', 1]  # Second principal component\n",
    "# time = moderate cyclers (14_med)\n",
    "pc1_14m = adata.obsm['X_pca'][copy_df['sample_type']=='Moderate_cyclers', 0]  # First principal component\n",
    "pc2_14m = adata.obsm['X_pca'][copy_df['sample_type']=='Moderate_cyclers', 1]  # Second principal component\n",
    "# time = non-cycling (14_high)\n",
    "pc1_14h = adata.obsm['X_pca'][copy_df['sample_type']=='Non-cycling', 0]  # First principal component\n",
    "pc2_14h = adata.obsm['X_pca'][copy_df['sample_type']=='Non-cycling', 1]  # Second principal component\n",
    "\n",
    "# Plot PC1 vs PC2\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(pc1_0, pc2_0, c='g', s=5) # plot day 0 cells\n",
    "plt.scatter(pc1_3, pc2_3, c='r', s=5) # plot day 3 cells\n",
    "plt.scatter(pc1_7, pc2_7, c='k', s=5) # plot day 7 cells\n",
    "plt.scatter(pc1_14l, pc2_14l, c='b', s=5) # plot day cycling (14_low) cells\n",
    "plt.scatter(pc1_14m, pc2_14m, c='c', s=5) # plot day moderate cycler (14_med) cells\n",
    "plt.scatter(pc1_14h, pc2_14h, c='m', s=5) # plot day non-cycling (14_high) cells\n",
    "\n",
    "plt.xlabel('PC1 ({:.1f}%)'.format(expl_var_pc1))\n",
    "plt.ylabel('PC2 ({:.1f}%)'.format(expl_var_pc2))\n",
    "plt.title('PCA Plot of PC1 vs PC2 colored by sample type')\n",
    "plt.legend(['Day 0','Day 3','Day 7','Day 14 - cycling','Day 14 - moderate cyclers','Day 14 - non-cycling']) \n",
    "# plt.savefig('/home/jolien/Notebooks/data_preprocessing/figures/PCA_colored_by_sample_type.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "sns.scatterplot(data=adata.obs, x=\"PC1\", y=\"PC2\", hue=\"sample_type\", size=5)\n",
    "\n",
    "plt.xlabel('PC1 ({:.1f}%)'.format(expl_var_pc1))\n",
    "plt.ylabel('PC2 ({:.1f}%)'.format(expl_var_pc2))\n",
    "plt.title('PCA Plot of PC1 vs PC2 colored by sample type')\n",
    "\n",
    "# plt.savefig('/home/jolien/Notebooks/data_preprocessing/figures/PCA_colored_by_sample_type_v2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "sns.kdeplot(data=adata.obs, x=\"PC1\", y=\"PC2\", hue=\"sample_type\") # contour plot\n",
    "\n",
    "plt.xlabel('PC1 ({:.1f}%)'.format(expl_var_pc1))\n",
    "plt.ylabel('PC2 ({:.1f}%)'.format(expl_var_pc2))\n",
    "plt.title('PCA density contour plot for sample types')\n",
    "\n",
    "# plt.savefig('/home/jolien/Notebooks/data_preprocessing/figures/PCA_contour_colored_by_sample_type.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "sns.kdeplot(data=adata.obs, x=\"PC1\", y=\"PC2\", hue=\"sample_type\",alpha=0.3, fill=True) # contour plot filled\n",
    "\n",
    "plt.xlabel('PC1 ({:.1f}%)'.format(expl_var_pc1))\n",
    "plt.ylabel('PC2 ({:.1f}%)'.format(expl_var_pc2))\n",
    "plt.title('PCA density contour plot for sample types')\n",
    "\n",
    "# plt.savefig('/home/jolien/Notebooks/data_preprocessing/figures/PCA_contour_colored_by_sample_type_filled.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check correlation PCs and time point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 2, figsize=(20, 18), sharey=True)\n",
    "\n",
    "pc_nr = 1\n",
    "\n",
    "for i, ax_row in enumerate(axes):\n",
    "    for j, ax in enumerate(ax_row):\n",
    "        \n",
    "        # Plot boxplots of PC per sample type\n",
    "        sns.boxplot(x='sample_type', y='PC'+str(pc_nr), data=adata.obs, ax=ax) \n",
    "        \n",
    "        # Add titles\n",
    "        ax.set_title(f'PC{pc_nr} grouped per sample type')\n",
    "        \n",
    "        # Add axis label\n",
    "        ax.set_ylabel(f\"PC{pc_nr}\")\n",
    "        \n",
    "        # Increment PC number\n",
    "        pc_nr += 1\n",
    "\n",
    "# fig.savefig('/home/jolien/Notebooks/data_preprocessing/figures/boxplots_PCs_per_sample_type.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether the difference in PC1 of group 0 and 3 is significant\n",
    "kruskal_result = stats.kruskal(\n",
    "    adata.obs['PC1'][adata.obs['sample_type'] == '0'],\n",
    "    adata.obs['PC1'][adata.obs['sample_type'] == '3']\n",
    ")\n",
    "\n",
    "print(\"Kruskal-Wallis p-value:\", kruskal_result.pvalue)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't know if I can use it when we don't have more digits for the p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cov(np.transpose(adata.obs['time_point']),np.transpose(adata.obs['PC1'])) # gives the same output as when I don't apply the transpose\n",
    "cov_PC1 = np.cov(adata.obs['time_point'],adata.obs['PC1'])\n",
    "print('covariance PC1 and time point:')\n",
    "print(cov_PC1)\n",
    "corr_PC1, _ = stats.pearsonr(adata.obs['time_point'],adata.obs['PC1'])\n",
    "print('Pearsons correlation PC1 and time point: %.3f' % corr_PC1,'\\n')\n",
    "\n",
    "cov_PC2 = np.cov(adata.obs['time_point'],adata.obs['PC2'])\n",
    "print('covariance PC2 and time point:')\n",
    "print(cov_PC2)\n",
    "corr_PC2, _ = stats.pearsonr(adata.obs['time_point'],adata.obs['PC2'])\n",
    "print('Pearsons correlation PC2 and time point: %.3f' % corr_PC2,'\\n')\n",
    "\n",
    "cov_PC3 = np.cov(adata.obs['time_point'],adata.obs['PC3'])\n",
    "print('covariance PC3 and time point:')\n",
    "print(cov_PC3)\n",
    "corr_PC3, _ = stats.pearsonr(adata.obs['time_point'],adata.obs['PC3'])\n",
    "print('Pearsons correlation PC3 and time point: %.3f' % corr_PC3,'\\n')\n",
    "\n",
    "cov_PC4 = np.cov(adata.obs['time_point'],adata.obs['PC4'])\n",
    "print('covariance PC4 and time point:')\n",
    "print(cov_PC4)\n",
    "corr_PC4, _ = stats.pearsonr(adata.obs['time_point'],adata.obs['PC4'])\n",
    "print('Pearsons correlation PC4 and time point: %.3f' % corr_PC4,'\\n')\n",
    "\n",
    "cov_PC5 = np.cov(adata.obs['time_point'],adata.obs['PC5'])\n",
    "print('covariance PC5 and time point:')\n",
    "print(cov_PC5)\n",
    "corr_PC5, _ = stats.pearsonr(adata.obs['time_point'],adata.obs['PC5'])\n",
    "print('Pearsons correlation PC5 and time point: %.3f' % corr_PC5,'\\n')\n",
    "\n",
    "cov_PC6 = np.cov(adata.obs['time_point'],adata.obs['PC6'])\n",
    "print('covariance PC6 and time point:')\n",
    "print(cov_PC6)\n",
    "corr_PC6, _ = stats.pearsonr(adata.obs['time_point'],adata.obs['PC6'])\n",
    "print('Pearsons correlation PC6 and time point: %.3f' % corr_PC6,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PC1 and time point have a positive covariance (off diagnal values in covariance matrix) and a correlation of 0.6 which indicates there is a dependency between PC1 and time point (moderate positive relationship)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Dimensionality reduction using PAGA and force-directed graphs as well as UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Louvain clustering\n",
    "sc.tl.louvain(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.paga(adata, groups='louvain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [6, 4.5]\n",
    "sc.pl.paga(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate force-directed graph with PAGA graph as initial cluster position\n",
    "sc.tl.draw_graph(adata, init_pos='paga', random_state=123) # Random seed to ensure consistency of plot for different runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate UMAP \n",
    "sc.tl.umap(adata,random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot force-directed graph with PAGA graph as initial cluster position\n",
    "sc.pl.draw_graph(adata, color=[\"louvain\", \"time_point\",\"sample_type\"], legend_loc='on data', save=\"_PAGA_batch_correction_all_groupings.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP plot\n",
    "sc.pl.umap(adata, color=['louvain','time_point','sample_type'],save=\"_UMAP_batch_correction_all_groupings.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot UMAP with coloring of cell fate which is based on the lineage barcodes\n",
    "sc.pl.umap(adata, color='fate_day_14',save=\"_UMAP_batch_correction_fate_day14.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_type_palette = {\n",
    "    '0': '#F560A6',  # Pink\n",
    "    '3': '#91307F',  # Purple\n",
    "    '7': '#2D0059',  # Dark purple\n",
    "    'Cycling': '#1f77b4',  # Blue\n",
    "    'Moderate_cyclers': '#ff7f0e',  # Orange\n",
    "    'Non-cycling': '#2ca02c',  # Green\n",
    "}\n",
    "\n",
    "sample_type_palette_time = {\n",
    "    0: '#F560A6',  # Pink\n",
    "    3: '#91307F',  # Purple\n",
    "    7: '#2D0059',  # Dark purple\n",
    "    14: '#5b5b5b',  # Grey\n",
    "}\n",
    "\n",
    "# Plot force-directed graph with PAGA graph as initial cluster position - legend next to plot\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "sc.pl.draw_graph(adata, color='louvain', legend_loc='on data', ax=axes[0], show=False)                                         # First plot with legend on data\n",
    "sc.pl.draw_graph(adata, color='time_point', ax=axes[1], palette=sample_type_palette_time, show=False)                          # Second plot \n",
    "sc.pl.draw_graph(adata, color='sample_type', ax=axes[2], palette=sample_type_palette, show=False)                              # Third plot \n",
    "\n",
    "# Save the combined plot\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Save AnnData object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.write('/home/jolien/Notebooks/data/preprocessed_data_bbknn_batchcorrection.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Load AnnData object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read preprocessed AnnData object\n",
    "adata_preprocessed = sc.read_h5ad('/home/jolien/Notebooks/data/preprocessed_data_bbknn_batchcorrection.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_type_palette = {\n",
    "    '0': '#F560A6',  # Pink\n",
    "    '3': '#91307F',  # Purple\n",
    "    '7': '#2D0059',  # Dark purple\n",
    "    'Cycling': '#1f77b4',  # Blue\n",
    "    'Moderate_cyclers': '#ff7f0e',  # Orange\n",
    "    'Non-cycling': '#2ca02c',  # Green\n",
    "}\n",
    "\n",
    "sample_type_palette_time = {\n",
    "    0: '#F560A6',  # Pink\n",
    "    3: '#91307F',  # Purple\n",
    "    7: '#2D0059',  # Dark purple\n",
    "    14: '#5b5b5b',  # Grey\n",
    "}\n",
    "\n",
    "# Plot force-directed graph with PAGA graph as initial cluster position - legend next to plot\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "sc.pl.draw_graph(adata_preprocessed, color='louvain', legend_loc='on data', ax=axes[0], show=False)                                         # First plot with legend on data\n",
    "sc.pl.draw_graph(adata_preprocessed, color='time_point', ax=axes[1], palette=sample_type_palette_time, show=False)                          # Second plot \n",
    "sc.pl.draw_graph(adata_preprocessed, color='sample_type', ax=axes[2], palette=sample_type_palette, show=False)                              # Third plot \n",
    "# sc.pl.draw_graph(adata_preprocessed, color='Predicted_cell_fate', ax=axes[2], palette=sample_type/_palette, show=False)                      # Third plot \n",
    "\n",
    "# Save the combined plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"/home/jolien/Notebooks/data_preprocessing/batch_correction/bbknn/figures/PAGA_batch_correction_all_groupings.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_env_grninference",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
